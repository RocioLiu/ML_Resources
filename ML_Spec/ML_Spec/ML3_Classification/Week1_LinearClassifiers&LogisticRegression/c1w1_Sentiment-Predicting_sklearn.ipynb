{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing Turi Create functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use SFrames to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "Convert each review to lower-case, and remove the punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      The First Years Massaging Action Teether\n",
       "review                    A favorite in our house!\n",
       "rating                                           5\n",
       "Name: 269, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.iloc[269]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using regular expression\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove punctuation using regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**. Make sure to fill n/a values in the **review** column with empty strings (if applicable). The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the **review** columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SoftPlay Twinkle Twinkle Elmo A Bedtime Book</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Summer Infant, Ultimate Training Pad - Twin Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Northstate Superyard Playgate Light Gray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>Munchkin Mozart Magic Cube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>Graco TotBloc Pack 'N Play with Carry Bag, Bug...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>Graco TotBloc Pack 'N Play with Carry Bag, Bug...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>Prince Lionheart Table Edge Guard with 4 Corne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>BABYBJORN Toilet Trainer - White/Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>BABYBJORN Potty Chair - Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>DEX Products Pregnancy Pillow PP-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>DEX Products Pregnancy Pillow PP-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>Playtex 3 Pack BPA Free VentAire Wide Bottles,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>The First Years Babypro Quick Serve Bottle War...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>The First Years Stack N Count Cups</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>Sliding Door Locks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>Philips AVENT BPA Free Classic Bottle Sealing ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8645</th>\n",
       "      <td>Graco - Duo Stroller Rain Cover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>Prince Lionheart Ultimate Wipes Warmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>Dr. Brown's Natural Flow Level 3 Standard Nipp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>4 Piece Kimono Gift Set in Pastel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10362</th>\n",
       "      <td>Wimmer-Ferguson Infant Stim-Mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>Wimmer-Ferguson Infant Stim-Mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11172</th>\n",
       "      <td>Fisher-Price Booster Seat, Blue/Green/Gray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11611</th>\n",
       "      <td>Fisher-Price Booster Seat, Blue/Green/Gray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11884</th>\n",
       "      <td>Quick Connection 900 Mhz Two Way Monitor System</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12059</th>\n",
       "      <td>Tiny Love Fruity Pals, Anna Banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12616</th>\n",
       "      <td>Munchkin Auto Seat Protector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13036</th>\n",
       "      <td>Badger Basket Moses Basket, Pink Gingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178385</th>\n",
       "      <td>Child Children Kids Safety Design Multi Use Au...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178435</th>\n",
       "      <td>Dream On Me Synergy&amp;nbsp;5 in 1 Convertible Cr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178462</th>\n",
       "      <td>Trend Lab Snuggle Monster 3 Piece Crib Bedding...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178555</th>\n",
       "      <td>Simple Wishes Hands Free Tie Back Breastpump B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178671</th>\n",
       "      <td>Wubbanub Owl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178865</th>\n",
       "      <td>Calmies - Natural Teether</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179364</th>\n",
       "      <td>Moonrest Firm - U Body Pillow Full Support and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179780</th>\n",
       "      <td>Jastore&amp;reg; Photography Prop Baby Costume Cut...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179857</th>\n",
       "      <td>Mud Pie Ornament, Baby's 1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179984</th>\n",
       "      <td>Fred 3-2-1 Lunch Rocket Utenils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180172</th>\n",
       "      <td>Dream On Me Zodiak Portable Playard, Navy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180503</th>\n",
       "      <td>Britax Marathon G4 Convertible Car Seat, Cowmo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180520</th>\n",
       "      <td>Britax Advocate G4 Convertible Car Seat, Zebra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180563</th>\n",
       "      <td>NSSTAR Fashionable Double Color Grid Pattern B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180610</th>\n",
       "      <td>6 Pc Blanket Infant Gift Set Pink Purple White...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180619</th>\n",
       "      <td>green Sprouts Aqua Bottle, Aqua, 10 Ounce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180729</th>\n",
       "      <td>Mokingtop 3pcs Girl Infant Baby Hat+Skirt+Shoe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180851</th>\n",
       "      <td>Susen Safe Shampoo Shower Bathing Protect Soft...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181203</th>\n",
       "      <td>Baby Deedee Sleepsies Footie (Baby) - Peacock-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181422</th>\n",
       "      <td>Carters Keep Me Close Blanket, Ecru Gift, Baby...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182018</th>\n",
       "      <td>juDanzy Hat, Tie &amp;amp; Leg Warmer Set for Baby...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182161</th>\n",
       "      <td>Cossettie's Compact Shopping Cart &amp;amp; High C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182435</th>\n",
       "      <td>Maxboost Designer Slim iPhone 5S/5 Case - Tick...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182460</th>\n",
       "      <td>Tommee Tippee Explora Insulated Drinking Cup, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183111</th>\n",
       "      <td>Atlanta Braves Infant Onesie 6 - 9 Months Team...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183143</th>\n",
       "      <td>The #1 Baby Nasal Aspirator - Free Carry Case,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183220</th>\n",
       "      <td>Dwinguler Eco-friendly Kid's Playmat - Sound P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183230</th>\n",
       "      <td>Graco Benton 5-in-1 Convertible Fixed-Side Cri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183241</th>\n",
       "      <td>Merry Muscles Ergonomic Jumper Exerciser Baby ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183344</th>\n",
       "      <td>SnappyNips Bottle Caps for converting Glass Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name review  rating\n",
       "38           SoftPlay Twinkle Twinkle Elmo A Bedtime Book    NaN       5\n",
       "58                              Our Baby Girl Memory Book    NaN       5\n",
       "721     Summer Infant, Ultimate Training Pad - Twin Ma...    NaN       5\n",
       "1050                Safety 1st Deluxe 4-in-1 Bath Station    NaN       1\n",
       "1183             Northstate Superyard Playgate Light Gray    NaN       5\n",
       "1373                           Munchkin Mozart Magic Cube    NaN       5\n",
       "1688    Graco TotBloc Pack 'N Play with Carry Bag, Bug...    NaN       5\n",
       "1689    Graco TotBloc Pack 'N Play with Carry Bag, Bug...    NaN       5\n",
       "2372    Prince Lionheart Table Edge Guard with 4 Corne...    NaN       2\n",
       "2409                 BABYBJORN Toilet Trainer - White/Red    NaN       5\n",
       "2838                          BABYBJORN Potty Chair - Red    NaN       4\n",
       "3257                  DEX Products Pregnancy Pillow PP-01    NaN       5\n",
       "3268                  DEX Products Pregnancy Pillow PP-01    NaN       1\n",
       "5036    Playtex 3 Pack BPA Free VentAire Wide Bottles,...    NaN       5\n",
       "5275    The First Years Babypro Quick Serve Bottle War...    NaN       1\n",
       "5513                   The First Years Stack N Count Cups    NaN       5\n",
       "7755                                   Sliding Door Locks    NaN       1\n",
       "7782    Philips AVENT BPA Free Classic Bottle Sealing ...    NaN       3\n",
       "8645                      Graco - Duo Stroller Rain Cover    NaN       5\n",
       "9456               Prince Lionheart Ultimate Wipes Warmer    NaN       5\n",
       "9826    Dr. Brown's Natural Flow Level 3 Standard Nipp...    NaN       1\n",
       "10340                   4 Piece Kimono Gift Set in Pastel    NaN       4\n",
       "10362                  Wimmer-Ferguson Infant Stim-Mobile    NaN       5\n",
       "10405                  Wimmer-Ferguson Infant Stim-Mobile    NaN       5\n",
       "11172          Fisher-Price Booster Seat, Blue/Green/Gray    NaN       5\n",
       "11611          Fisher-Price Booster Seat, Blue/Green/Gray    NaN       5\n",
       "11884     Quick Connection 900 Mhz Two Way Monitor System    NaN       1\n",
       "12059                  Tiny Love Fruity Pals, Anna Banana    NaN       5\n",
       "12616                        Munchkin Auto Seat Protector    NaN       4\n",
       "13036            Badger Basket Moses Basket, Pink Gingham    NaN       5\n",
       "...                                                   ...    ...     ...\n",
       "178385  Child Children Kids Safety Design Multi Use Au...    NaN       1\n",
       "178435  Dream On Me Synergy&nbsp;5 in 1 Convertible Cr...    NaN       3\n",
       "178462  Trend Lab Snuggle Monster 3 Piece Crib Bedding...    NaN       5\n",
       "178555  Simple Wishes Hands Free Tie Back Breastpump B...    NaN       4\n",
       "178671                                       Wubbanub Owl    NaN       5\n",
       "178865                          Calmies - Natural Teether    NaN       5\n",
       "179364  Moonrest Firm - U Body Pillow Full Support and...    NaN       4\n",
       "179780  Jastore&reg; Photography Prop Baby Costume Cut...    NaN       2\n",
       "179857                       Mud Pie Ornament, Baby's 1st    NaN       5\n",
       "179984                    Fred 3-2-1 Lunch Rocket Utenils    NaN       5\n",
       "180172          Dream On Me Zodiak Portable Playard, Navy    NaN       5\n",
       "180503  Britax Marathon G4 Convertible Car Seat, Cowmo...    NaN       5\n",
       "180520     Britax Advocate G4 Convertible Car Seat, Zebra    NaN       5\n",
       "180563  NSSTAR Fashionable Double Color Grid Pattern B...    NaN       4\n",
       "180610  6 Pc Blanket Infant Gift Set Pink Purple White...    NaN       5\n",
       "180619          green Sprouts Aqua Bottle, Aqua, 10 Ounce    NaN       5\n",
       "180729  Mokingtop 3pcs Girl Infant Baby Hat+Skirt+Shoe...    NaN       3\n",
       "180851  Susen Safe Shampoo Shower Bathing Protect Soft...    NaN       2\n",
       "181203  Baby Deedee Sleepsies Footie (Baby) - Peacock-...    NaN       1\n",
       "181422  Carters Keep Me Close Blanket, Ecru Gift, Baby...    NaN       1\n",
       "182018  juDanzy Hat, Tie &amp; Leg Warmer Set for Baby...    NaN       5\n",
       "182161  Cossettie's Compact Shopping Cart &amp; High C...    NaN       1\n",
       "182435  Maxboost Designer Slim iPhone 5S/5 Case - Tick...    NaN       5\n",
       "182460  Tommee Tippee Explora Insulated Drinking Cup, ...    NaN       4\n",
       "183111  Atlanta Braves Infant Onesie 6 - 9 Months Team...    NaN       5\n",
       "183143  The #1 Baby Nasal Aspirator - Free Carry Case,...    NaN       5\n",
       "183220  Dwinguler Eco-friendly Kid's Playmat - Sound P...    NaN       5\n",
       "183230  Graco Benton 5-in-1 Convertible Fixed-Side Cri...    NaN       5\n",
       "183241  Merry Muscles Ergonomic Jumper Exerciser Baby ...    NaN       5\n",
       "183344  SnappyNips Bottle Caps for converting Glass Be...    NaN       5\n",
       "\n",
       "[829 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[products['review'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['review'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''}) # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['review'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove punctuation characters\n",
    "# match everything that is not a lowercase a-z, uppercase A-Z, or digits 0-9, and replaces them with a space.\n",
    "def remove_punctuation(text):\n",
    "    text = text.lower()\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", \" \", str(text))\n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "## methods 2\n",
    "# def remove_punctuation(text):\n",
    "#     import string\n",
    "#     return text.translate(None, string.punctuation) \n",
    "\n",
    "# products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    these flannel wipes are ok  but in my opinion ...\n",
       "1    it came early and was not disappointed  i love...\n",
       "2    very soft and comfortable and warmer than it l...\n",
       "3    this is a product well worth the purchase   i ...\n",
       "4    all of my kids have cried non stop when i trie...\n",
       "Name: review_clean, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['review_clean'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transform the reviews into word-counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word_count(sentence):\n",
    "#     w_list = sentence.lower().split()\n",
    "#     w_count = dict()\n",
    "    \n",
    "#     for w in w_list:\n",
    "#         w_count[w] = w_count.get(w, 0) + 1.0\n",
    "        \n",
    "#     return w_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products['word_count'] = review_without_punctuation.apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'it': 3.0, 'came': 1.0, 'early': 1.0, 'and': ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'very': 1.0, 'soft': 1.0, 'and': 2.0, 'comfor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'this': 4.0, 'is': 4.0, 'a': 2.0, 'product': ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'all': 2.0, 'of': 1.0, 'my': 1.0, 'kids': 2.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'when': 2.0, 'the': 6.0, 'binky': 3.0, 'fairy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                          word_count  sentiment  \n",
       "1  {'it': 3.0, 'came': 1.0, 'early': 1.0, 'and': ...          1  \n",
       "2  {'very': 1.0, 'soft': 1.0, 'and': 2.0, 'comfor...          1  \n",
       "3  {'this': 4.0, 'is': 4.0, 'a': 2.0, 'product': ...          1  \n",
       "4  {'all': 2.0, 'of': 1.0, 'my': 1.0, 'kids': 2.0...          1  \n",
       "5  {'when': 2.0, 'the': 6.0, 'binky': 3.0, 'fairy...          1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the word_count column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1.0, 'favorite': 1.0, 'in': 1.0, 'our': 1.0, 'house': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# products.iloc[269]['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166752"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed  i love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>this is a product well worth the purchase   i ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>all of my kids have cried non stop when i trie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>when the binky fairy came to our house  we did...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Tale of Baby's Days with Peter Rabbit</td>\n",
       "      <td>Lovely book, it's bound tightly so you may not...</td>\n",
       "      <td>4</td>\n",
       "      <td>lovely book  it s bound tightly so you may not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>Perfect for new parents. We were able to keep ...</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect for new parents  we were able to keep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>A friend of mine pinned this product on Pinter...</td>\n",
       "      <td>5</td>\n",
       "      <td>a friend of mine pinned this product on pinter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>this has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>i love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "1                               Planetwise Wipe Pouch   \n",
       "2                 Annas Dream Full Quilt with 2 Shams   \n",
       "3   Stop Pacifier Sucking without tears with Thumb...   \n",
       "4   Stop Pacifier Sucking without tears with Thumb...   \n",
       "5   Stop Pacifier Sucking without tears with Thumb...   \n",
       "6             A Tale of Baby's Days with Peter Rabbit   \n",
       "7   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "8   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "9   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "10  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "1   it came early and was not disappointed. i love...       5   \n",
       "2   Very soft and comfortable and warmer than it l...       5   \n",
       "3   This is a product well worth the purchase.  I ...       5   \n",
       "4   All of my kids have cried non-stop when I trie...       5   \n",
       "5   When the Binky Fairy came to our house, we did...       5   \n",
       "6   Lovely book, it's bound tightly so you may not...       4   \n",
       "7   Perfect for new parents. We were able to keep ...       5   \n",
       "8   A friend of mine pinned this product on Pinter...       5   \n",
       "9   This has been an easy way for my nanny to reco...       4   \n",
       "10  I love this journal and our nanny uses it ever...       4   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "1   it came early and was not disappointed  i love...          1  \n",
       "2   very soft and comfortable and warmer than it l...          1  \n",
       "3   this is a product well worth the purchase   i ...          1  \n",
       "4   all of my kids have cried non stop when i trie...          1  \n",
       "5   when the binky fairy came to our house  we did...          1  \n",
       "6   lovely book  it s bound tightly so you may not...          1  \n",
       "7   perfect for new parents  we were able to keep ...          1  \n",
       "8   a friend of mine pinned this product on pinter...          1  \n",
       "9   this has been an easy way for my nanny to reco...          1  \n",
       "10  i love this journal and our nanny uses it ever...          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating: +1 if rating > 3 else -1)\n",
    "\n",
    "products.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'review', 'rating', 'review_clean', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = products['sentiment']\n",
    "X = products.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133401\n",
      "33351\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCLA02-NB01.ipynb\u001b[m\u001b[m                   \u001b[34mamazon_baby.sframe\u001b[m\u001b[m\r\n",
      "W1_Sentiment-Predicting.ipynb      module-2-assignment-test-idx.json\r\n",
      "amazon_baby.csv                    module-2-assignment-train-idx.json\r\n",
      "\u001b[34mamazon_baby.gl\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('module-2-assignment-train-idx.json') as json_file:\n",
    "    train_idx = json.load(json_file)\n",
    "    \n",
    "with open('module-2-assignment-test-idx.json') as json_file:\n",
    "    test_idx = json.load(json_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = products.iloc[train_idx]\n",
    "test_data = products.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416 33336\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review  \n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as **bag-of-word features**. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "* Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "\n",
    "* Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "\n",
    "* Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix **train_matrix**.\n",
    "\n",
    "* Using the same mapping between words and columns, convert the test data into a sparse matrix **test_matrix**.\n",
    "\n",
    "The following cell uses `CountVectorizer` in scikit-learn. Notice the **token_pattern** argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\b\\\\w+\\\\b', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<133416x57445 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 7431855 stored elements in Compressed Sparse Row format>,\n",
       " <33336x57445 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1856335 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1881)\t1\n",
      "  (0, 2558)\t1\n",
      "  (0, 3878)\t1\n",
      "  (0, 4295)\t1\n",
      "  (0, 4519)\t1\n",
      "  (0, 5405)\t1\n",
      "  (0, 5998)\t2\n",
      "  (0, 6920)\t1\n",
      "  (0, 7002)\t2\n",
      "  (0, 13307)\t1\n",
      "  (0, 17651)\t1\n",
      "  (0, 18987)\t1\n",
      "  (0, 21169)\t1\n",
      "  (0, 24017)\t1\n",
      "  (0, 24153)\t1\n",
      "  (0, 24214)\t1\n",
      "  (0, 24707)\t1\n",
      "  (0, 24983)\t2\n",
      "  (0, 25568)\t3\n",
      "  (0, 26014)\t1\n",
      "  (0, 26441)\t1\n",
      "  (0, 27290)\t2\n",
      "  (0, 27315)\t1\n",
      "  (0, 27368)\t1\n",
      "  (0, 27900)\t1\n",
      "  :\t:\n",
      "  (33335, 19504)\t1\n",
      "  (33335, 21679)\t1\n",
      "  (33335, 24214)\t1\n",
      "  (33335, 25568)\t2\n",
      "  (33335, 27368)\t1\n",
      "  (33335, 28179)\t1\n",
      "  (33335, 30286)\t1\n",
      "  (33335, 31011)\t1\n",
      "  (33335, 31412)\t1\n",
      "  (33335, 33125)\t1\n",
      "  (33335, 33789)\t1\n",
      "  (33335, 34789)\t1\n",
      "  (33335, 39376)\t1\n",
      "  (33335, 39652)\t1\n",
      "  (33335, 40847)\t1\n",
      "  (33335, 44723)\t1\n",
      "  (33335, 49012)\t1\n",
      "  (33335, 50208)\t1\n",
      "  (33335, 50504)\t2\n",
      "  (33335, 50800)\t1\n",
      "  (33335, 50854)\t1\n",
      "  (33335, 50968)\t1\n",
      "  (33335, 54678)\t1\n",
      "  (33335, 55735)\t1\n",
      "  (33335, 56661)\t1\n"
     ]
    }
   ],
   "source": [
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the test data must be transformed in the same way as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. We should create an instance of the [LogisticRegression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and then call the method `fit()` to train the classifier. This model should use the sparse word count matrix (**train_matrix**)as features and the column **sentiment** of train_data as the target. Use the default values for other parameters. Call this model `sentiment_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = LinearRegression()\n",
    "sentiment_model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.07624343, -0.12644704,  0.16097678, ...,  0.0173788 ,\n",
       "       -0.18990994,  0.93812441])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sentiment_model.coef_))\n",
    "sentiment_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6282252612088051"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be over 100,000 coefficients in this sentiment_model. Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (>= 0, which is actually nonnegative) coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30517"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in sentiment_model.coef_ if i >= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
