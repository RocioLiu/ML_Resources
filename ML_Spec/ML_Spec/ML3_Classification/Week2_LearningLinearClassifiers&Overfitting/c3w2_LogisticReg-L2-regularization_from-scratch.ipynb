{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 regularization\n",
    "\n",
    "The goal of this second notebook is to implement your own logistic regression classifier with L2 regularization. You will do the following:\n",
    "\n",
    " * Extract features from Amazon product reviews.\n",
    " * Convert an dataframe into a NumPy array.\n",
    " * Write a function to compute the derivative of log likelihood function with an L2 penalty with respect to a single coefficient.\n",
    " * Implement gradient ascent with an L2 penalty.\n",
    " * Empirically explore how the L2 penalty can ameliorate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = os.path.join('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'c3w2_Quiz-2.jpeg',\n",
       " 'amazon_baby_subset.csv',\n",
       " 'amazon_baby_subset.sframe',\n",
       " 'module-4-assignment-validation-idx.json',\n",
       " 'important_words.json',\n",
       " 'module-4-assignment-train-idx.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process review dataset\n",
    "**1**. For this assignment, we will use the same subset of the Amazon product review dataset that we used in Module 3 assignment. The subset was chosen to contain similar numbers of positive and negative reviews, as the original dataset consisted of mostly positive reviews. \n",
    "\n",
    "Load the dataset into a data frame named `products`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv(os.path.join(data_home, 'amazon_baby_subset.csv'))\n",
    "\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. Just like we did previously, we will work with a hand-curated list of important words extracted from the review data. We will also perform 2 simple data transformations:\n",
    "\n",
    "* Remove punctuation\n",
    "* Compute word counts (only for the **important_words**)\n",
    "\n",
    "We start with the first item as follows:\n",
    "\n",
    "* If your tool supports it, fill n/a values in the review column with empty strings. The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the review columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''}) # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(data_home, 'important_words.json'), 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a function **remove_punctuation** that takes a line of text and removes all punctuation from that text. The function should be analogous to the following Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = text.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the **remove_punctuation** function on every element of the **review** column and assign the result to the new column **review_clean**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. Now we proceed with the second item. For each word in **important_words**, we compute a count for the number of times the word occurs in the review. We will store this count in a separate column (one for each word). The result of this feature processing is a single column for each word in **important_words** which keeps a count of the number of times the respective word occurs in the review text.\n",
    "\n",
    "**Note**: There are several ways of doing this. One way is to create an anonymous function that counts the occurrence of a particular word and apply it to every element in the **review_clean** column. Repeat this step for every word in **important_words**. Your code should be analogous to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out the words into individual columns\n",
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda x: x.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. After #2 and #3, the data frame **products** should contain one column for each of the 193 **important_words**. As an example, the column **perfect** contains a count of the number of times the word **prefect** occurs in each of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "2  My daughter had her 1st baby over a year ago S...     1    0      0     0   \n",
       "3  One of babys first and favorite books and it i...     0    0      0     0   \n",
       "4  Very cute interactive book My son loves this b...     0    0      1     0   \n",
       "\n",
       "   use  ...  seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0  ...      0        0           0     0       0       0    0    0   \n",
       "1    0  ...      0        0           0     0       0       0    0    0   \n",
       "2    0  ...      0        0           0     0       0       0    0    0   \n",
       "3    0  ...      0        0           0     0       0       0    0    0   \n",
       "4    0  ...      0        0           0     0       0       1    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split\n",
    "\n",
    "**5**. We split the data into a train-validation split with 80% of the data in the training set and 20% of the data in the validation set. We use `seed=2` so that everyone gets the same result.\n",
    "\n",
    "**Note:** In previous assignments, we have called this a **train-test split**. However, the portion of data that we don't train on will be used to help **select model parameters**. Thus, this portion of data should be called a **validation set**. Recall that examining performance of various potential models (i.e. models with different parameters) should be on a validation set, while evaluation of selected model should always be on a test set. Typically, we would also save a portion of the data (a real test set) to test our final model on or use cross-validation on the training set to select our final model. But for the learning purposes of this assignment, we won't do that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data, validation_data = train_test_split(products, test_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using SFrame, download the list of indices for the training and validation sets:\n",
    "\n",
    "* module-4-assignment-train-idx.json\n",
    "* module-4-assignment-validation-idx.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(data_home, 'module-4-assignment-train-idx.json')) as json_file:\n",
    "    train_idx = json.load(json_file)\n",
    "    \n",
    "with open(os.path.join(data_home, 'module-4-assignment-validation-idx.json')) as json_file:\n",
    "    validation_idx = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "print(train_idx[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = products.iloc[train_idx]\n",
    "validation_data = products.iloc[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set  : 42361 data points\n",
      "Validation set: 10711 data points\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set  : {len(train_data)} data points\")\n",
    "print(f\"Validation set: {len(validation_data)} data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data frame to multi-dimensional array\n",
    "**6**. Convert **train_data** and **validation_data** into multi-dimensional arrays.\n",
    "\n",
    "Using the function given in #8 of Module 3 assignment, extract two arrays **feature_matrix_train** and **sentiment_train** from **train_data**. The 2D array **feature_matrix_train** would contain the content of the columns given by the list **important_words**. The 1D array **sentiment_train** would contain the content of the column sentiment. Do the same for **validation_data**, producing the arrays **feature_matrix_valid** and **sentiment_valid**. The code should be analogous to this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(df, features, label):\n",
    "    df.loc[:, 'constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_2d = df.loc[:, features].values\n",
    "    label_1d = df.loc[:, label].values\n",
    "    \n",
    "    return features_2d, label_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "feature_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
    "feature_valid, sentiment_valid = get_numpy_data(validation_data, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data.shape     : (42361, 194), (42361,)\n",
      "Validation_data.shape: (10711, 194), (10711,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train_data.shape     : {feature_train.shape}, {sentiment_train.shape}\")\n",
    "print(f\"Validation_data.shape: {feature_valid.shape}, {sentiment_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building on logistic regression with no L2 penalty assignment\n",
    "\n",
    "**7**. Let us now build on Module 3 assignment. Recall from lecture that the link function for logistic regression can be defined as:\n",
    "\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ is given by the word counts of **important_words** in the review $\\mathbf{x}_i$. \n",
    "\n",
    "We will use the **same code** as in this past assignment to make probability predictions since this part is not affected by the L2 penalty.  (Only the way in which the coefficients are learned is affected by the addition of a regularization term.) Refer to #10 of Module 3 assignment in order to obtain the function **predict_probability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predictions = 1 / (1 + np.exp(-score))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding L2 penalty\n",
    "**8**. Let us now work on extending logistic regression with L2 regularization. As discussed in the lectures, the L2 regularization is particularly useful in preventing overfitting. In this assignment, we will explore L2 regularization in detail.\n",
    "\n",
    "Recall from lecture and the previous assignment that for logistic regression without an L2 penalty, the derivative of the log likelihood function is:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "#### Adding L2 penalty to the derivative\n",
    "\n",
    "**9**. It takes only a small modification to add a L2 penalty. All terms indicated in **red** refer to terms that were added due to an **L2 penalty**.\n",
    "\n",
    "* Recall from the lecture that the link function is still the sigmoid:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "* We add the L2 penalty term to the per-coefficient derivative of log likelihood:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "\n",
    "The **per-coefficient derivative for logistic regression with an L2 penalty** is as follows:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "and for the **intercept** term, we have\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_0} = \\sum_{i=1}^N h_0(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "**Note**: *As we did in the Regression course, we do not apply the L2 penalty on the intercept. A large intercept does not necessarily indicate overfitting because the intercept is not associated with any particular feature*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. Unlike its counterpart in the last assignment, the function accepts five arguments:\n",
    " * `errors` vector whose $i$-th value contains $(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w}))$ \n",
    " * `feature` vector whose $i$-th value contains $h_j(\\mathbf{x}_i)$  \n",
    " * `coefficient` containing the current value of $j$-th coefficient $w_j$.\n",
    " * `l2_penalty` representing the L2 penalty constant $\\lambda$\n",
    " * `feature_is_constant` a Boolean value indicating whether the $j$-th feature is constant or not.\n",
    " \n",
    "The function should do the following:\n",
    "\n",
    "* Take the five parameters as above.\n",
    "* Compute the dot product of **errors** and **feature** and save the result to **derivative**.\n",
    "* If **feature_is_constant** is False, subtract the L2 penalty term from **derivative**. Otherwise, do nothing.\n",
    "* Return **derivative**.\n",
    "\n",
    "The function should be analogous to the following Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant):\n",
    "    \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(feature, errors)\n",
    "    \n",
    "    # add L2 penalty term for any feature that isn't the intercept.\n",
    "    if not feature_is_constant:\n",
    "        derivative -= 2 * l2_penalty * coefficient\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** In the code above, was the intercept term regularized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: No, the intercept term was not regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10**. To verify the correctness of the gradient ascent algorithm, we provide a function for computing log likelihood (which we recall from the last assignment was a topic detailed in an advanced optional video, and used here for its numerical stability).\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment == +1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    ll = np.sum((indicator-1)*scores-np.log(1+np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Does the term with L2 regularization increase or decrease $\\ell\\ell(\\mathbf{w})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: It decreases $\\ell\\ell(\\mathbf{w})$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11**. The logistic regression function looks almost like the one in the last assignment, with a minor modification to account for the L2 penalty.\n",
    "\n",
    "Write a function **logistic_regression_with_L2** to fit a logistic regression model under L2 regularization.  \n",
    "\n",
    "The function accepts the following parameters:  \n",
    "\n",
    "* **feature_matrix**: 2D array of features\n",
    "* **sentiment**: 1D array of class labels\n",
    "* **initial_coefficients**: 1D array containing initial values of coefficients\n",
    "* **step_size**: a parameter controlling the size of the gradient steps\n",
    "* **l2_penalty**: the L2 penalty constant λ\n",
    "* **max_iter**: number of iterations to run gradient ascent\n",
    "\n",
    "The function returns the last set of coefficients after performing gradient ascent.\n",
    "\n",
    "The function carries out the following steps:\n",
    "\n",
    "1. Initialize vector **coefficients** to **initial_coefficients**.\n",
    "2. Predict the class probability $P(y_i=+1|x_i,w)$ using your **predict_probability** function and save it to variable **predictions**.\n",
    "3. Compute indicator value for $(y_i=+1)$ by comparing **sentiment** against +1. Save it to variable **indicator**.\n",
    "4. Compute the errors as difference between **indicator** and **predictions**. Save the errors to variable errors.\n",
    "5. For each $j$-th coefficient, compute the per-coefficient derivative by calling **feature_derivative_L2** with the $j$-th column of **feature_matrix**. Don't forget to supply the L2 penalty. Then increment the $j$-th coefficient by (step_size*derivative).\n",
    "6. Once in a while, insert code to print out the log likelihood.\n",
    "7. Repeat steps 2-6 for **max_iter** times.\n",
    "\n",
    "At the end of day, your code should be analogous to the following Python function (with blanks filled in):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(max_iter):\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment == +1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            is_intercept = (j == 0)\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j], coefficients[j], l2_penalty, is_intercept)\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            coefficients[j] = coefficients[j] + step_size*derivative\n",
    "            \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            ll = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print(f\"iteration {itr:>{int(np.ceil(np.log10(max_iter)))}}: log likelihood of observed labels = {ll:.8f}\")\n",
    "            \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore effects of L2 regularization\n",
    "\n",
    "**12**. Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. **As iterations pass, the log likelihood should increase**.\n",
    "\n",
    "Let us train models with increasing amounts of regularization, starting with no L2 penalty, which is equivalent to our previous logistic regression implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 6 models with L2 penalty values 0, 4, 10, 1e2, 1e3, and 1e5. Use the following values for the other parameters:\n",
    "\n",
    "* **feature_matrix = feature_matrix_train** extracted in #7\n",
    "* **sentiment = sentiment_train** extracted in #7\n",
    "* **initial_coefficients** = a 194-dimensional vector filled with zeros\n",
    "* **step_size** = 5e-6\n",
    "* **max_iter** = 501\n",
    "\n",
    "Save the 6 sets of coefficients as **coefficients_0_penalty**, **coefficients_4_penalty**, **coefficients_10_penalty**, **coefficients_1e2_penalty**, **coefficients_1e3_penalty**, and **coefficients_1e5_penalty** respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39138303\n",
      "iteration   1: log likelihood of observed labels = -29003.71259047\n",
      "iteration   2: log likelihood of observed labels = -28834.66187288\n",
      "iteration   3: log likelihood of observed labels = -28671.70781507\n",
      "iteration   4: log likelihood of observed labels = -28514.43078198\n",
      "iteration   5: log likelihood of observed labels = -28362.48344665\n",
      "iteration   6: log likelihood of observed labels = -28215.56713122\n",
      "iteration   7: log likelihood of observed labels = -28073.41743783\n",
      "iteration   8: log likelihood of observed labels = -27935.79536396\n",
      "iteration   9: log likelihood of observed labels = -27802.48168669\n",
      "iteration  10: log likelihood of observed labels = -27673.27331484\n",
      "iteration  11: log likelihood of observed labels = -27547.98083656\n",
      "iteration  12: log likelihood of observed labels = -27426.42679977\n",
      "iteration  13: log likelihood of observed labels = -27308.44444728\n",
      "iteration  14: log likelihood of observed labels = -27193.87673876\n",
      "iteration  15: log likelihood of observed labels = -27082.57555831\n",
      "iteration  20: log likelihood of observed labels = -26570.43059938\n",
      "iteration  30: log likelihood of observed labels = -25725.48742389\n",
      "iteration  40: log likelihood of observed labels = -25055.53326910\n",
      "iteration  50: log likelihood of observed labels = -24509.63590026\n",
      "iteration  60: log likelihood of observed labels = -24054.97906083\n",
      "iteration  70: log likelihood of observed labels = -23669.51640848\n",
      "iteration  80: log likelihood of observed labels = -23337.89167628\n",
      "iteration  90: log likelihood of observed labels = -23049.07066021\n",
      "iteration 100: log likelihood of observed labels = -22794.90974921\n",
      "iteration 200: log likelihood of observed labels = -21283.29527353\n",
      "iteration 300: log likelihood of observed labels = -20570.97485473\n",
      "iteration 400: log likelihood of observed labels = -20152.21466944\n",
      "iteration 500: log likelihood of observed labels = -19876.62333410\n"
     ]
    }
   ],
   "source": [
    "# l2_penalty = 0\n",
    "coefficients_0_penalty = logistic_regression_with_L2(feature_train, \n",
    "                                                     sentiment_train, \n",
    "                                                     initial_coefficients=np.zeros(194), \n",
    "                                                     step_size=5e-6, \n",
    "                                                     l2_penalty=0, \n",
    "                                                     max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39508175\n",
      "iteration   1: log likelihood of observed labels = -29003.73417180\n",
      "iteration   2: log likelihood of observed labels = -28834.71441858\n",
      "iteration   3: log likelihood of observed labels = -28671.80345068\n",
      "iteration   4: log likelihood of observed labels = -28514.58077957\n",
      "iteration   5: log likelihood of observed labels = -28362.69830317\n",
      "iteration   6: log likelihood of observed labels = -28215.85663259\n",
      "iteration   7: log likelihood of observed labels = -28073.79071393\n",
      "iteration   8: log likelihood of observed labels = -27936.26093762\n",
      "iteration   9: log likelihood of observed labels = -27803.04751805\n",
      "iteration  10: log likelihood of observed labels = -27673.94684207\n",
      "iteration  11: log likelihood of observed labels = -27548.76901327\n",
      "iteration  12: log likelihood of observed labels = -27427.33612958\n",
      "iteration  13: log likelihood of observed labels = -27309.48101569\n",
      "iteration  14: log likelihood of observed labels = -27195.04624253\n",
      "iteration  15: log likelihood of observed labels = -27083.88333261\n",
      "iteration  20: log likelihood of observed labels = -26572.49874392\n",
      "iteration  30: log likelihood of observed labels = -25729.32604153\n",
      "iteration  40: log likelihood of observed labels = -25061.34245801\n",
      "iteration  50: log likelihood of observed labels = -24517.52091982\n",
      "iteration  60: log likelihood of observed labels = -24064.99093939\n",
      "iteration  70: log likelihood of observed labels = -23681.67373669\n",
      "iteration  80: log likelihood of observed labels = -23352.19298741\n",
      "iteration  90: log likelihood of observed labels = -23065.50180166\n",
      "iteration 100: log likelihood of observed labels = -22813.44844580\n",
      "iteration 200: log likelihood of observed labels = -21321.14164794\n",
      "iteration 300: log likelihood of observed labels = -20624.98634439\n",
      "iteration 400: log likelihood of observed labels = -20219.92048845\n",
      "iteration 500: log likelihood of observed labels = -19956.11341777\n"
     ]
    }
   ],
   "source": [
    "# l2_penalty = 4\n",
    "coefficients_4_penalty = logistic_regression_with_L2(feature_train, \n",
    "                                                     sentiment_train, \n",
    "                                                     initial_coefficients=np.zeros(194), \n",
    "                                                     step_size=5e-6, \n",
    "                                                     l2_penalty=4, \n",
    "                                                     max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.40062984\n",
      "iteration   1: log likelihood of observed labels = -29003.76654163\n",
      "iteration   2: log likelihood of observed labels = -28834.79322654\n",
      "iteration   3: log likelihood of observed labels = -28671.94687528\n",
      "iteration   4: log likelihood of observed labels = -28514.80571589\n",
      "iteration   5: log likelihood of observed labels = -28363.02048079\n",
      "iteration   6: log likelihood of observed labels = -28216.29071186\n",
      "iteration   7: log likelihood of observed labels = -28074.35036891\n",
      "iteration   8: log likelihood of observed labels = -27936.95892966\n",
      "iteration   9: log likelihood of observed labels = -27803.89576265\n",
      "iteration  10: log likelihood of observed labels = -27674.95647005\n",
      "iteration  11: log likelihood of observed labels = -27549.95042714\n",
      "iteration  12: log likelihood of observed labels = -27428.69905549\n",
      "iteration  13: log likelihood of observed labels = -27311.03455140\n",
      "iteration  14: log likelihood of observed labels = -27196.79890162\n",
      "iteration  15: log likelihood of observed labels = -27085.84308528\n",
      "iteration  20: log likelihood of observed labels = -26575.59697506\n",
      "iteration  30: log likelihood of observed labels = -25735.07304608\n",
      "iteration  40: log likelihood of observed labels = -25070.03447306\n",
      "iteration  50: log likelihood of observed labels = -24529.31188025\n",
      "iteration  60: log likelihood of observed labels = -24079.95349572\n",
      "iteration  70: log likelihood of observed labels = -23699.83199186\n",
      "iteration  80: log likelihood of observed labels = -23373.54108747\n",
      "iteration  90: log likelihood of observed labels = -23090.01500055\n",
      "iteration 100: log likelihood of observed labels = -22841.08995135\n",
      "iteration 200: log likelihood of observed labels = -21377.25595328\n",
      "iteration 300: log likelihood of observed labels = -20704.63995428\n",
      "iteration 400: log likelihood of observed labels = -20319.25685307\n",
      "iteration 500: log likelihood of observed labels = -20072.16321721\n"
     ]
    }
   ],
   "source": [
    "# l2_penalty = 10\n",
    "coefficients_10_penalty = logistic_regression_with_L2(feature_train, \n",
    "                                                      sentiment_train, \n",
    "                                                      initial_coefficients=np.zeros(194), \n",
    "                                                      step_size=5e-6, \n",
    "                                                      l2_penalty=10, \n",
    "                                                      max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.48385120\n",
      "iteration   1: log likelihood of observed labels = -29004.25177457\n",
      "iteration   2: log likelihood of observed labels = -28835.97382190\n",
      "iteration   3: log likelihood of observed labels = -28674.09410083\n",
      "iteration   4: log likelihood of observed labels = -28518.17112932\n",
      "iteration   5: log likelihood of observed labels = -28367.83774654\n",
      "iteration   6: log likelihood of observed labels = -28222.77708939\n",
      "iteration   7: log likelihood of observed labels = -28082.70799392\n",
      "iteration   8: log likelihood of observed labels = -27947.37595368\n",
      "iteration   9: log likelihood of observed labels = -27816.54738615\n",
      "iteration  10: log likelihood of observed labels = -27690.00588850\n",
      "iteration  11: log likelihood of observed labels = -27567.54970126\n",
      "iteration  12: log likelihood of observed labels = -27448.98991327\n",
      "iteration  13: log likelihood of observed labels = -27334.14912742\n",
      "iteration  14: log likelihood of observed labels = -27222.86041863\n",
      "iteration  15: log likelihood of observed labels = -27114.96648229\n",
      "iteration  20: log likelihood of observed labels = -26621.50201299\n",
      "iteration  30: log likelihood of observed labels = -25819.72803950\n",
      "iteration  40: log likelihood of observed labels = -25197.34035501\n",
      "iteration  50: log likelihood of observed labels = -24701.03698195\n",
      "iteration  60: log likelihood of observed labels = -24296.66378580\n",
      "iteration  70: log likelihood of observed labels = -23961.38842316\n",
      "iteration  80: log likelihood of observed labels = -23679.38088853\n",
      "iteration  90: log likelihood of observed labels = -23439.31824267\n",
      "iteration 100: log likelihood of observed labels = -23232.88192018\n",
      "iteration 200: log likelihood of observed labels = -22133.50726528\n",
      "iteration 300: log likelihood of observed labels = -21730.03957488\n",
      "iteration 400: log likelihood of observed labels = -21545.87572145\n",
      "iteration 500: log likelihood of observed labels = -21451.95551390\n"
     ]
    }
   ],
   "source": [
    "# l2_penalty = 1e2\n",
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_train, \n",
    "                                                       sentiment_train, \n",
    "                                                       initial_coefficients=np.zeros(194), \n",
    "                                                       step_size=5e-6, \n",
    "                                                       l2_penalty=1e2, \n",
    "                                                       max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29180.31606471\n",
      "iteration   1: log likelihood of observed labels = -29009.07176112\n",
      "iteration   2: log likelihood of observed labels = -28847.62378912\n",
      "iteration   3: log likelihood of observed labels = -28695.14439397\n",
      "iteration   4: log likelihood of observed labels = -28550.95060743\n",
      "iteration   5: log likelihood of observed labels = -28414.45771129\n",
      "iteration   6: log likelihood of observed labels = -28285.15124375\n",
      "iteration   7: log likelihood of observed labels = -28162.56976044\n",
      "iteration   8: log likelihood of observed labels = -28046.29387744\n",
      "iteration   9: log likelihood of observed labels = -27935.93902900\n",
      "iteration  10: log likelihood of observed labels = -27831.15045502\n",
      "iteration  11: log likelihood of observed labels = -27731.59955260\n",
      "iteration  12: log likelihood of observed labels = -27636.98108219\n",
      "iteration  13: log likelihood of observed labels = -27547.01092670\n",
      "iteration  14: log likelihood of observed labels = -27461.42422295\n",
      "iteration  15: log likelihood of observed labels = -27379.97375625\n",
      "iteration  20: log likelihood of observed labels = -27027.18208317\n",
      "iteration  30: log likelihood of observed labels = -26527.22737267\n",
      "iteration  40: log likelihood of observed labels = -26206.59048765\n",
      "iteration  50: log likelihood of observed labels = -25995.96903148\n",
      "iteration  60: log likelihood of observed labels = -25854.95710284\n",
      "iteration  70: log likelihood of observed labels = -25759.08109950\n",
      "iteration  80: log likelihood of observed labels = -25693.05688014\n",
      "iteration  90: log likelihood of observed labels = -25647.09929349\n",
      "iteration 100: log likelihood of observed labels = -25614.81468705\n",
      "iteration 200: log likelihood of observed labels = -25536.20998919\n",
      "iteration 300: log likelihood of observed labels = -25532.57691220\n",
      "iteration 400: log likelihood of observed labels = -25532.35543765\n",
      "iteration 500: log likelihood of observed labels = -25532.33970049\n"
     ]
    }
   ],
   "source": [
    "# l2_penalty = 1e3\n",
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_train, \n",
    "                                                       sentiment_train, \n",
    "                                                       initial_coefficients=np.zeros(194), \n",
    "                                                       step_size=5e-6, \n",
    "                                                       l2_penalty=1e3, \n",
    "                                                       max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29271.85955115\n",
      "iteration   1: log likelihood of observed labels = -29271.71006589\n",
      "iteration   2: log likelihood of observed labels = -29271.65738833\n",
      "iteration   3: log likelihood of observed labels = -29271.61189923\n",
      "iteration   4: log likelihood of observed labels = -29271.57079975\n",
      "iteration   5: log likelihood of observed labels = -29271.53358505\n",
      "iteration   6: log likelihood of observed labels = -29271.49988440\n",
      "iteration   7: log likelihood of observed labels = -29271.46936584\n",
      "iteration   8: log likelihood of observed labels = -29271.44172890\n",
      "iteration   9: log likelihood of observed labels = -29271.41670149\n",
      "iteration  10: log likelihood of observed labels = -29271.39403722\n",
      "iteration  11: log likelihood of observed labels = -29271.37351294\n",
      "iteration  12: log likelihood of observed labels = -29271.35492661\n",
      "iteration  13: log likelihood of observed labels = -29271.33809523\n",
      "iteration  14: log likelihood of observed labels = -29271.32285309\n",
      "iteration  15: log likelihood of observed labels = -29271.30905015\n",
      "iteration  20: log likelihood of observed labels = -29271.25729150\n",
      "iteration  30: log likelihood of observed labels = -29271.20657205\n",
      "iteration  40: log likelihood of observed labels = -29271.18775997\n",
      "iteration  50: log likelihood of observed labels = -29271.18078247\n",
      "iteration  60: log likelihood of observed labels = -29271.17819447\n",
      "iteration  70: log likelihood of observed labels = -29271.17723457\n",
      "iteration  80: log likelihood of observed labels = -29271.17687853\n",
      "iteration  90: log likelihood of observed labels = -29271.17674648\n",
      "iteration 100: log likelihood of observed labels = -29271.17669750\n",
      "iteration 200: log likelihood of observed labels = -29271.17666862\n",
      "iteration 300: log likelihood of observed labels = -29271.17666862\n",
      "iteration 400: log likelihood of observed labels = -29271.17666862\n",
      "iteration 500: log likelihood of observed labels = -29271.17666862\n"
     ]
    }
   ],
   "source": [
    "# l2_penalty = 1e5\n",
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_train, \n",
    "                                                       sentiment_train, \n",
    "                                                       initial_coefficients=np.zeros(194), \n",
    "                                                       step_size=5e-6, \n",
    "                                                       l2_penalty=1e5, \n",
    "                                                       max_iter=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare coefficients\n",
    "\n",
    "**13**. We now compare the **coefficients** for each of the models that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
    "\n",
    "Below is a simple helper function that will help us create this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **the coefficients trained with L2 penalty 0**, find the 5 most positive words (with largest positive coefficients). Save them to **positive_words**. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to **negative_words**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'word':['(intercept)'] + important_words})\n",
    "\n",
    "def add_coefficients_to_table(coef_array, coef_name):\n",
    "    coef_df[coef_name] = coef_array\n",
    "    return coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficients [L2=0]</th>\n",
       "      <th>coefficients [L2=4]</th>\n",
       "      <th>coefficients [L2=10]</th>\n",
       "      <th>coefficients [L2=1e2]</th>\n",
       "      <th>coefficients [L2=1e3]</th>\n",
       "      <th>coefficients [L2=1e5]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(intercept)</td>\n",
       "      <td>-0.063742</td>\n",
       "      <td>-0.063143</td>\n",
       "      <td>-0.062256</td>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.073877</td>\n",
       "      <td>0.072360</td>\n",
       "      <td>0.059752</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.801625</td>\n",
       "      <td>0.796897</td>\n",
       "      <td>0.789935</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.376012</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1.058554</td>\n",
       "      <td>1.050856</td>\n",
       "      <td>1.039529</td>\n",
       "      <td>0.896644</td>\n",
       "      <td>0.418354</td>\n",
       "      <td>0.009042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>use</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.017326</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.287021</td>\n",
       "      <td>-0.286027</td>\n",
       "      <td>-0.284564</td>\n",
       "      <td>-0.265993</td>\n",
       "      <td>-0.188662</td>\n",
       "      <td>-0.008127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.007043</td>\n",
       "      <td>-0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>easy</td>\n",
       "      <td>0.984559</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.967362</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.401904</td>\n",
       "      <td>0.008808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>0.524419</td>\n",
       "      <td>0.521385</td>\n",
       "      <td>0.516917</td>\n",
       "      <td>0.460235</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.005941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seat</td>\n",
       "      <td>-0.086968</td>\n",
       "      <td>-0.086125</td>\n",
       "      <td>-0.084883</td>\n",
       "      <td>-0.069109</td>\n",
       "      <td>-0.017718</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>old</td>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.206037</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>0.105074</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>well</td>\n",
       "      <td>0.453866</td>\n",
       "      <td>0.450969</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>0.194926</td>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>get</td>\n",
       "      <td>-0.196835</td>\n",
       "      <td>-0.196100</td>\n",
       "      <td>-0.195017</td>\n",
       "      <td>-0.181251</td>\n",
       "      <td>-0.122728</td>\n",
       "      <td>-0.004578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>also</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.157246</td>\n",
       "      <td>0.155899</td>\n",
       "      <td>0.139153</td>\n",
       "      <td>0.080918</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>really</td>\n",
       "      <td>-0.017906</td>\n",
       "      <td>-0.017745</td>\n",
       "      <td>-0.017508</td>\n",
       "      <td>-0.014481</td>\n",
       "      <td>-0.004448</td>\n",
       "      <td>-0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>son</td>\n",
       "      <td>0.128396</td>\n",
       "      <td>0.127761</td>\n",
       "      <td>0.126828</td>\n",
       "      <td>0.115192</td>\n",
       "      <td>0.070411</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>-0.072281</td>\n",
       "      <td>-0.072065</td>\n",
       "      <td>-0.069480</td>\n",
       "      <td>-0.057581</td>\n",
       "      <td>-0.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bought</td>\n",
       "      <td>-0.151817</td>\n",
       "      <td>-0.150917</td>\n",
       "      <td>-0.149594</td>\n",
       "      <td>-0.132884</td>\n",
       "      <td>-0.072431</td>\n",
       "      <td>-0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>product</td>\n",
       "      <td>-0.263330</td>\n",
       "      <td>-0.262328</td>\n",
       "      <td>-0.260854</td>\n",
       "      <td>-0.242391</td>\n",
       "      <td>-0.167962</td>\n",
       "      <td>-0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>good</td>\n",
       "      <td>0.156507</td>\n",
       "      <td>0.155270</td>\n",
       "      <td>0.153445</td>\n",
       "      <td>0.129972</td>\n",
       "      <td>0.047879</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>daughter</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>0.261775</td>\n",
       "      <td>0.259357</td>\n",
       "      <td>0.228685</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>much</td>\n",
       "      <td>-0.013247</td>\n",
       "      <td>-0.013295</td>\n",
       "      <td>-0.013366</td>\n",
       "      <td>-0.014326</td>\n",
       "      <td>-0.015219</td>\n",
       "      <td>-0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.052484</td>\n",
       "      <td>1.043903</td>\n",
       "      <td>1.031265</td>\n",
       "      <td>0.870794</td>\n",
       "      <td>0.345870</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stroller</td>\n",
       "      <td>-0.037533</td>\n",
       "      <td>-0.036988</td>\n",
       "      <td>-0.036186</td>\n",
       "      <td>-0.025990</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>put</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>-0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>months</td>\n",
       "      <td>-0.067995</td>\n",
       "      <td>-0.067315</td>\n",
       "      <td>-0.066314</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>car</td>\n",
       "      <td>0.193364</td>\n",
       "      <td>0.191904</td>\n",
       "      <td>0.189754</td>\n",
       "      <td>0.162531</td>\n",
       "      <td>0.072719</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>still</td>\n",
       "      <td>0.188508</td>\n",
       "      <td>0.187071</td>\n",
       "      <td>0.184955</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>back</td>\n",
       "      <td>-0.268954</td>\n",
       "      <td>-0.267419</td>\n",
       "      <td>-0.265161</td>\n",
       "      <td>-0.236730</td>\n",
       "      <td>-0.134671</td>\n",
       "      <td>-0.003988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>started</td>\n",
       "      <td>-0.153174</td>\n",
       "      <td>-0.151852</td>\n",
       "      <td>-0.149905</td>\n",
       "      <td>-0.125084</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>anything</td>\n",
       "      <td>-0.186801</td>\n",
       "      <td>-0.185242</td>\n",
       "      <td>-0.182943</td>\n",
       "      <td>-0.153602</td>\n",
       "      <td>-0.057284</td>\n",
       "      <td>-0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>last</td>\n",
       "      <td>-0.099469</td>\n",
       "      <td>-0.098692</td>\n",
       "      <td>-0.097547</td>\n",
       "      <td>-0.083001</td>\n",
       "      <td>-0.034797</td>\n",
       "      <td>-0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>company</td>\n",
       "      <td>-0.276548</td>\n",
       "      <td>-0.274151</td>\n",
       "      <td>-0.270621</td>\n",
       "      <td>-0.225839</td>\n",
       "      <td>-0.084898</td>\n",
       "      <td>-0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>come</td>\n",
       "      <td>-0.032009</td>\n",
       "      <td>-0.031804</td>\n",
       "      <td>-0.031502</td>\n",
       "      <td>-0.027685</td>\n",
       "      <td>-0.014185</td>\n",
       "      <td>-0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>returned</td>\n",
       "      <td>-0.572707</td>\n",
       "      <td>-0.567518</td>\n",
       "      <td>-0.559870</td>\n",
       "      <td>-0.462056</td>\n",
       "      <td>-0.150021</td>\n",
       "      <td>-0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>maybe</td>\n",
       "      <td>-0.224076</td>\n",
       "      <td>-0.222015</td>\n",
       "      <td>-0.218976</td>\n",
       "      <td>-0.180192</td>\n",
       "      <td>-0.058149</td>\n",
       "      <td>-0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>took</td>\n",
       "      <td>-0.046445</td>\n",
       "      <td>-0.046199</td>\n",
       "      <td>-0.045838</td>\n",
       "      <td>-0.041422</td>\n",
       "      <td>-0.025566</td>\n",
       "      <td>-0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>broke</td>\n",
       "      <td>-0.555195</td>\n",
       "      <td>-0.550209</td>\n",
       "      <td>-0.542861</td>\n",
       "      <td>-0.448989</td>\n",
       "      <td>-0.148726</td>\n",
       "      <td>-0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>makes</td>\n",
       "      <td>-0.009023</td>\n",
       "      <td>-0.008764</td>\n",
       "      <td>-0.008382</td>\n",
       "      <td>-0.003467</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>stay</td>\n",
       "      <td>-0.300563</td>\n",
       "      <td>-0.297920</td>\n",
       "      <td>-0.294024</td>\n",
       "      <td>-0.244247</td>\n",
       "      <td>-0.083709</td>\n",
       "      <td>-0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>instead</td>\n",
       "      <td>-0.193123</td>\n",
       "      <td>-0.191418</td>\n",
       "      <td>-0.188907</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>-0.054125</td>\n",
       "      <td>-0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>idea</td>\n",
       "      <td>-0.465370</td>\n",
       "      <td>-0.461130</td>\n",
       "      <td>-0.454879</td>\n",
       "      <td>-0.374890</td>\n",
       "      <td>-0.118469</td>\n",
       "      <td>-0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>head</td>\n",
       "      <td>-0.110472</td>\n",
       "      <td>-0.109559</td>\n",
       "      <td>-0.108215</td>\n",
       "      <td>-0.090992</td>\n",
       "      <td>-0.032986</td>\n",
       "      <td>-0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>said</td>\n",
       "      <td>-0.098049</td>\n",
       "      <td>-0.097331</td>\n",
       "      <td>-0.096274</td>\n",
       "      <td>-0.082875</td>\n",
       "      <td>-0.037594</td>\n",
       "      <td>-0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>less</td>\n",
       "      <td>-0.136801</td>\n",
       "      <td>-0.135652</td>\n",
       "      <td>-0.133958</td>\n",
       "      <td>-0.112360</td>\n",
       "      <td>-0.042260</td>\n",
       "      <td>-0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>went</td>\n",
       "      <td>-0.106836</td>\n",
       "      <td>-0.106003</td>\n",
       "      <td>-0.104776</td>\n",
       "      <td>-0.089294</td>\n",
       "      <td>-0.039417</td>\n",
       "      <td>-0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>working</td>\n",
       "      <td>-0.320363</td>\n",
       "      <td>-0.317559</td>\n",
       "      <td>-0.313427</td>\n",
       "      <td>-0.260764</td>\n",
       "      <td>-0.092334</td>\n",
       "      <td>-0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>high</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>unit</td>\n",
       "      <td>-0.196121</td>\n",
       "      <td>-0.194516</td>\n",
       "      <td>-0.192153</td>\n",
       "      <td>-0.162210</td>\n",
       "      <td>-0.066568</td>\n",
       "      <td>-0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>seems</td>\n",
       "      <td>0.058308</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.049753</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>picture</td>\n",
       "      <td>-0.196906</td>\n",
       "      <td>-0.195273</td>\n",
       "      <td>-0.192866</td>\n",
       "      <td>-0.162143</td>\n",
       "      <td>-0.061171</td>\n",
       "      <td>-0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>completely</td>\n",
       "      <td>-0.277845</td>\n",
       "      <td>-0.275461</td>\n",
       "      <td>-0.271947</td>\n",
       "      <td>-0.227098</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>-0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.173191</td>\n",
       "      <td>0.171640</td>\n",
       "      <td>0.169352</td>\n",
       "      <td>0.140022</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>buying</td>\n",
       "      <td>-0.132197</td>\n",
       "      <td>-0.131083</td>\n",
       "      <td>-0.129441</td>\n",
       "      <td>-0.108471</td>\n",
       "      <td>-0.040331</td>\n",
       "      <td>-0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>babies</td>\n",
       "      <td>0.052494</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.044805</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>won</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tub</td>\n",
       "      <td>-0.166745</td>\n",
       "      <td>-0.165367</td>\n",
       "      <td>-0.163338</td>\n",
       "      <td>-0.137693</td>\n",
       "      <td>-0.054778</td>\n",
       "      <td>-0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>almost</td>\n",
       "      <td>-0.031916</td>\n",
       "      <td>-0.031621</td>\n",
       "      <td>-0.031186</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.007361</td>\n",
       "      <td>-0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>either</td>\n",
       "      <td>-0.228852</td>\n",
       "      <td>-0.226793</td>\n",
       "      <td>-0.223758</td>\n",
       "      <td>-0.184986</td>\n",
       "      <td>-0.061138</td>\n",
       "      <td>-0.000980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficients [L2=0]  coefficients [L2=4]  \\\n",
       "0    (intercept)            -0.063742            -0.063143   \n",
       "1           baby             0.074073             0.073994   \n",
       "2            one             0.012753             0.012495   \n",
       "3          great             0.801625             0.796897   \n",
       "4           love             1.058554             1.050856   \n",
       "5            use            -0.000104             0.000163   \n",
       "6          would            -0.287021            -0.286027   \n",
       "7           like            -0.003384            -0.003442   \n",
       "8           easy             0.984559             0.977600   \n",
       "9         little             0.524419             0.521385   \n",
       "10          seat            -0.086968            -0.086125   \n",
       "11           old             0.208912             0.207749   \n",
       "12          well             0.453866             0.450969   \n",
       "13           get            -0.196835            -0.196100   \n",
       "14          also             0.158163             0.157246   \n",
       "15        really            -0.017906            -0.017745   \n",
       "16           son             0.128396             0.127761   \n",
       "17          time            -0.072429            -0.072281   \n",
       "18        bought            -0.151817            -0.150917   \n",
       "19       product            -0.263330            -0.262328   \n",
       "20          good             0.156507             0.155270   \n",
       "21      daughter             0.263418             0.261775   \n",
       "22          much            -0.013247            -0.013295   \n",
       "23         loves             1.052484             1.043903   \n",
       "24      stroller            -0.037533            -0.036988   \n",
       "25           put            -0.000330            -0.000323   \n",
       "26        months            -0.067995            -0.067315   \n",
       "27           car             0.193364             0.191904   \n",
       "28         still             0.188508             0.187071   \n",
       "29          back            -0.268954            -0.267419   \n",
       "..           ...                  ...                  ...   \n",
       "164      started            -0.153174            -0.151852   \n",
       "165     anything            -0.186801            -0.185242   \n",
       "166         last            -0.099469            -0.098692   \n",
       "167      company            -0.276548            -0.274151   \n",
       "168         come            -0.032009            -0.031804   \n",
       "169     returned            -0.572707            -0.567518   \n",
       "170        maybe            -0.224076            -0.222015   \n",
       "171         took            -0.046445            -0.046199   \n",
       "172        broke            -0.555195            -0.550209   \n",
       "173        makes            -0.009023            -0.008764   \n",
       "174         stay            -0.300563            -0.297920   \n",
       "175      instead            -0.193123            -0.191418   \n",
       "176         idea            -0.465370            -0.461130   \n",
       "177         head            -0.110472            -0.109559   \n",
       "178         said            -0.098049            -0.097331   \n",
       "179         less            -0.136801            -0.135652   \n",
       "180         went            -0.106836            -0.106003   \n",
       "181      working            -0.320363            -0.317559   \n",
       "182         high             0.003326             0.003282   \n",
       "183         unit            -0.196121            -0.194516   \n",
       "184        seems             0.058308             0.057905   \n",
       "185      picture            -0.196906            -0.195273   \n",
       "186   completely            -0.277845            -0.275461   \n",
       "187         wish             0.173191             0.171640   \n",
       "188       buying            -0.132197            -0.131083   \n",
       "189       babies             0.052494             0.052130   \n",
       "190          won             0.004960             0.004907   \n",
       "191          tub            -0.166745            -0.165367   \n",
       "192       almost            -0.031916            -0.031621   \n",
       "193       either            -0.228852            -0.226793   \n",
       "\n",
       "     coefficients [L2=10]  coefficients [L2=1e2]  coefficients [L2=1e3]  \\\n",
       "0               -0.062256              -0.050438               0.000054   \n",
       "1                0.073877               0.072360               0.059752   \n",
       "2                0.012115               0.007247              -0.008761   \n",
       "3                0.789935               0.701425               0.376012   \n",
       "4                1.039529               0.896644               0.418354   \n",
       "5                0.000556               0.005481               0.017326   \n",
       "6               -0.284564              -0.265993              -0.188662   \n",
       "7               -0.003527              -0.004635              -0.007043   \n",
       "8                0.967362               0.838245               0.401904   \n",
       "9                0.516917               0.460235               0.251221   \n",
       "10              -0.084883              -0.069109              -0.017718   \n",
       "11               0.206037               0.184332               0.105074   \n",
       "12               0.446700               0.392304               0.194926   \n",
       "13              -0.195017              -0.181251              -0.122728   \n",
       "14               0.155899               0.139153               0.080918   \n",
       "15              -0.017508              -0.014481              -0.004448   \n",
       "16               0.126828               0.115192               0.070411   \n",
       "17              -0.072065              -0.069480              -0.057581   \n",
       "18              -0.149594              -0.132884              -0.072431   \n",
       "19              -0.260854              -0.242391              -0.167962   \n",
       "20               0.153445               0.129972               0.047879   \n",
       "21               0.259357               0.228685               0.117158   \n",
       "22              -0.013366              -0.014326              -0.015219   \n",
       "23               1.031265               0.870794               0.345870   \n",
       "24              -0.036186              -0.025990               0.005912   \n",
       "25              -0.000312              -0.000127               0.001529   \n",
       "26              -0.066314              -0.053594              -0.013083   \n",
       "27               0.189754               0.162531               0.072719   \n",
       "28               0.184955               0.158163               0.068491   \n",
       "29              -0.265161              -0.236730              -0.134671   \n",
       "..                    ...                    ...                    ...   \n",
       "164             -0.149905              -0.125084              -0.045084   \n",
       "165             -0.182943              -0.153602              -0.057284   \n",
       "166             -0.097547              -0.083001              -0.034797   \n",
       "167             -0.270621              -0.225839              -0.084898   \n",
       "168             -0.031502              -0.027685              -0.014185   \n",
       "169             -0.559870              -0.462056              -0.150021   \n",
       "170             -0.218976              -0.180192              -0.058149   \n",
       "171             -0.045838              -0.041422              -0.025566   \n",
       "172             -0.542861              -0.448989              -0.148726   \n",
       "173             -0.008382              -0.003467               0.008757   \n",
       "174             -0.294024              -0.244247              -0.083709   \n",
       "175             -0.188907              -0.156863              -0.054125   \n",
       "176             -0.454879              -0.374890              -0.118469   \n",
       "177             -0.108215              -0.090992              -0.032986   \n",
       "178             -0.096274              -0.082875              -0.037594   \n",
       "179             -0.133958              -0.112360              -0.042260   \n",
       "180             -0.104776              -0.089294              -0.039417   \n",
       "181             -0.313427              -0.260764              -0.092334   \n",
       "182              0.003217               0.002404               0.000236   \n",
       "183             -0.192153              -0.162210              -0.066568   \n",
       "184              0.057312               0.049753               0.022875   \n",
       "185             -0.192866              -0.162143              -0.061171   \n",
       "186             -0.271947              -0.227098              -0.081775   \n",
       "187              0.169352               0.140022               0.044374   \n",
       "188             -0.129441              -0.108471              -0.040331   \n",
       "189              0.051594               0.044805               0.021026   \n",
       "190              0.004830               0.003848               0.001084   \n",
       "191             -0.163338              -0.137693              -0.054778   \n",
       "192             -0.031186              -0.025604              -0.007361   \n",
       "193             -0.223758              -0.184986              -0.061138   \n",
       "\n",
       "     coefficients [L2=1e5]  \n",
       "0                 0.011362  \n",
       "1                 0.001784  \n",
       "2                -0.001827  \n",
       "3                 0.008950  \n",
       "4                 0.009042  \n",
       "5                 0.000418  \n",
       "6                -0.008127  \n",
       "7                -0.000827  \n",
       "8                 0.008808  \n",
       "9                 0.005941  \n",
       "10                0.000611  \n",
       "11                0.002741  \n",
       "12                0.003945  \n",
       "13               -0.004578  \n",
       "14                0.001929  \n",
       "15               -0.000340  \n",
       "16                0.001552  \n",
       "17               -0.002805  \n",
       "18               -0.001985  \n",
       "19               -0.006211  \n",
       "20                0.000266  \n",
       "21                0.002401  \n",
       "22               -0.000839  \n",
       "23                0.006150  \n",
       "24                0.001326  \n",
       "25               -0.000097  \n",
       "26               -0.000157  \n",
       "27                0.001765  \n",
       "28                0.000976  \n",
       "29               -0.003988  \n",
       "..                     ...  \n",
       "164              -0.000877  \n",
       "165              -0.001053  \n",
       "166              -0.000775  \n",
       "167              -0.001719  \n",
       "168              -0.000426  \n",
       "169              -0.002225  \n",
       "170              -0.000945  \n",
       "171              -0.000772  \n",
       "172              -0.002182  \n",
       "173               0.000255  \n",
       "174              -0.001310  \n",
       "175              -0.000925  \n",
       "176              -0.001627  \n",
       "177              -0.000502  \n",
       "178              -0.000947  \n",
       "179              -0.000873  \n",
       "180              -0.001006  \n",
       "181              -0.001674  \n",
       "182              -0.000062  \n",
       "183              -0.001567  \n",
       "184               0.000329  \n",
       "185              -0.001151  \n",
       "186              -0.001421  \n",
       "187               0.000468  \n",
       "188              -0.000792  \n",
       "189               0.000365  \n",
       "190               0.000017  \n",
       "191              -0.000936  \n",
       "192              -0.000125  \n",
       "193              -0.000980  \n",
       "\n",
       "[194 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_coefficients_to_table(coefficients_0_penalty, 'coefficients [L2=0]')\n",
    "add_coefficients_to_table(coefficients_4_penalty, 'coefficients [L2=4]')\n",
    "add_coefficients_to_table(coefficients_10_penalty, 'coefficients [L2=10]')\n",
    "add_coefficients_to_table(coefficients_1e2_penalty, 'coefficients [L2=1e2]')\n",
    "add_coefficients_to_table(coefficients_1e3_penalty, 'coefficients [L2=1e3]')\n",
    "add_coefficients_to_table(coefficients_1e5_penalty, 'coefficients [L2=1e5]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **the coefficients trained with L2 penalty 0**, find the 5 most positive words (with largest positive coefficients). Save them to **positive_words**. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to **negative_words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most positive words: \n",
      "\n",
      "4        love\n",
      "23      loves\n",
      "8        easy\n",
      "34    perfect\n",
      "3       great\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "most_positive_idx = sorted(range(len(coef_df['coefficients [L2=0]'])), \n",
    "                           key=lambda i: coef_df['coefficients [L2=0]'][i], reverse=True)\n",
    "\n",
    "positive_words = coef_df['word'].iloc[most_positive_idx[:5]]\n",
    "\n",
    "print(f\"5 most positive words: \\n\\n{positive_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most negative words: \n",
      "\n",
      "106    disappointed\n",
      "97            money\n",
      "114          return\n",
      "113           waste\n",
      "169        returned\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "most_negative_idx = sorted(range(len(coef_df['coefficients [L2=0]'])), \n",
    "                           key=lambda i: coef_df['coefficients [L2=0]'][i])\n",
    "\n",
    "negative_words = coef_df['word'].iloc[most_negative_idx[:5]]\n",
    "\n",
    "print(f\"5 most negative words: \\n\\n{negative_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the following is **not** listed in either **positive_words** or **negative_words**?\n",
    "\n",
    "**Answer**: quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14**. 14. Let us observe the effect of increasing L2 penalty on the 10 words just selected. Make a plot of the coefficients for the 10 words over the different values of L2 penalty.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "* First, extract rows corresponding to **positive_words**. Do the same for **negative_words**.\n",
    "* Then plot each of the extracted rows. The x axis should be L2 penalty and the y axis should be the coefficient value.\n",
    "* Use log scale for the x axis, as the L2 penalty values are exponentially spaced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "def make_coefficient_plot(coef_df, positive_words, negative_words, l2_penalty_list):\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = coef_df[coef_df['word'].isin(positive_words)]\n",
    "    table_negative_words = coef_df[coef_df['word'].isin(negative_words)]\n",
    "    del table_positive_words['word']\n",
    "    del table_negative_words['word']\n",
    "    \n",
    "    for i in range(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].values.flatten(),\n",
    "                 '-', label=positive_words.iloc[i], linewidth=2.0, color=color)\n",
    "        \n",
    "    for i in range(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].values.flatten(),\n",
    "                 '-', label=negative_words.iloc[i], linewidth=2.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_coefficient_plot(coef_df, positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: (True/False) All coefficients consistently get smaller in size as the L2 penalty is increased.\n",
    "\n",
    "**Answer**: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: (True/False) The relative order of coefficients is preserved as the L2 penalty is increased. (For example, if the coefficient for 'cat' was more positive than that for 'dog', this remains true as the L2 penalty increases.)\n",
    "\n",
    "**Answer**: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "**15**. Now, let us compute the accuracy of the classifier model. Recall that the accuracy is given by\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "\n",
    "Recall from lecture that that the class prediction is calculated using\n",
    "$$\n",
    "\\hat{y}_i = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & h(\\mathbf{x}_i)^T\\mathbf{w} > 0 \\\\\n",
    "      -1 & h(\\mathbf{x}_i)^T\\mathbf{w} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "**Note**: It is important to know that the model prediction code doesn't change even with the addition of an L2 penalty. The only thing that changes is the estimated coefficients used in this prediction.\n",
    "\n",
    "Based on the above, we will use the same code that was used in Module 3 assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    y_hat = np.array([+1 if s > 0 else -1 for s in scores])\n",
    "    \n",
    "    num_correct = (y_hat == sentiment).sum()\n",
    "    accuracy = num_correct / len(y_hat)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compare the accuracy on the **training data** and **validation data** for all the models that were trained in this assignment.  We first calculate the accuracy values and then build a simple report summarizing the performance for the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "train_accuracy[0] = cal_accuracy(feature_train, sentiment_train, coefficients_0_penalty)\n",
    "train_accuracy[4] = cal_accuracy(feature_train, sentiment_train, coefficients_4_penalty)\n",
    "train_accuracy[10] = cal_accuracy(feature_train, sentiment_train, coefficients_10_penalty)\n",
    "train_accuracy[1e2] = cal_accuracy(feature_train, sentiment_train, coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = cal_accuracy(feature_train, sentiment_train, coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = cal_accuracy(feature_train, sentiment_train, coefficients_1e5_penalty)\n",
    "\n",
    "valid_accuracy = {}\n",
    "valid_accuracy[0] = cal_accuracy(feature_valid, sentiment_valid, coefficients_0_penalty)\n",
    "valid_accuracy[4] = cal_accuracy(feature_valid, sentiment_valid, coefficients_4_penalty)\n",
    "valid_accuracy[10] = cal_accuracy(feature_valid, sentiment_valid, coefficients_10_penalty)\n",
    "valid_accuracy[1e2] = cal_accuracy(feature_valid, sentiment_valid, coefficients_1e2_penalty)\n",
    "valid_accuracy[1e3] = cal_accuracy(feature_valid, sentiment_valid, coefficients_1e3_penalty)\n",
    "valid_accuracy[1e5] = cal_accuracy(feature_valid, sentiment_valid, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7851561577866434,\n",
       " 4: 0.7851089445480512,\n",
       " 10: 0.7849909114515711,\n",
       " 100.0: 0.7839758268218409,\n",
       " 1000.0: 0.7758551497839994,\n",
       " 100000.0: 0.6803663747314747}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty = 0\n",
      "train accuracy = 0.7851561577866434, validation_accuracy = 0.781439641490057\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 4\n",
      "train accuracy = 0.7851089445480512, validation_accuracy = 0.7815330034543927\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 10\n",
      "train accuracy = 0.7849909114515711, validation_accuracy = 0.7817197273830642\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100\n",
      "train accuracy = 0.7839758268218409, validation_accuracy = 0.781066193632714\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 1000\n",
      "train accuracy = 0.7758551497839994, validation_accuracy = 0.7713565493417982\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100000\n",
      "train accuracy = 0.6803663747314747, validation_accuracy = 0.667818130893474\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(valid_accuracy.keys()):\n",
    "    print(\"L2 penalty = %g\" % key)\n",
    "    print(\"train accuracy = %s, validation_accuracy = %s\" % (train_accuracy[key], valid_accuracy[key]))\n",
    "    print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.tight_layout(pad=1.08, h_pad=None, w_pad=None, rect=None)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional. Plot accuracy on training and validation sets over choice of L2 penalty.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "sorted_list = sorted(train_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], 'bo-', linewidth=4, label='Training accuracy')\n",
    "sorted_list = sorted(valid_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], 'ro-', linewidth=4, label='Validation accuracy')\n",
    "plt.xscale('symlog')\n",
    "plt.axis([0, 1e3, 0.78, 0.786])\n",
    "plt.legend(loc='lower left')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the **highest** accuracy on the **training** data?  \n",
    "**Answer**: L2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the **highest** accuracy on the **validation** data?  \n",
    "**Answer**: L2 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Does the **highest** accuracy on the **training** data imply that the model is the best one?  \n",
    "**Answer**: not really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
