{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Geron10_Intro to ANN with Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RocioLiu/ML_Resources/blob/master/Geron10_Intro_to_ANN_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbR0FGfNytMG",
        "colab_type": "text"
      },
      "source": [
        "## Implementing MLPs with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JT7xvdAx4Px",
        "colab_type": "text"
      },
      "source": [
        "### Building an Image Classifier Using the Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ4keHlc94mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzSxTkxu953A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "72cec08c-8fb9-45d8-988e-0ae2d349044a"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFf1MU7W99wM",
        "colab_type": "code",
        "outputId": "6a4182d7-4288-4047-b375-87090a414910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp03I5hG-CAF",
        "colab_type": "code",
        "outputId": "8f65261b-7248-4136-988a-3888a00541b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_full.dtype"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcuPc7Bt-GcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeVMwrFY-_Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPhWNJ31_CIC",
        "colab_type": "code",
        "outputId": "4d33b7ac-e7b8-4382-ecb4-aa84a8058b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names[y_train[0]]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkQSnO_HyJCi",
        "colab_type": "text"
      },
      "source": [
        "#### Creating the Model Using the Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqaW2c0G_cyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4c352cd9-78ba-434a-c7de-f97750b0987f"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(10, activation = 'softmax'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 08:47:57.492129 139636251805568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RblqPDlcFObh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, activation = 'relu'),\n",
        "    keras.layers.Dense(100, activation = 'relu'),\n",
        "    keras.layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKxRbzsSHc09",
        "colab_type": "code",
        "outputId": "3cab3dec-afb1-4d9c-e67f-562eae0d4565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.layers\n",
        "model.layers[1].name\n",
        "#model.get_layer('dense_3').name"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dense_3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-EJnkMKZ23",
        "colab_type": "code",
        "outputId": "7602474c-bf03-401a-c407-0c61d1610584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "weights, biases = model.layers[1].get_weights()\n",
        "weights"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01503728, -0.05699985,  0.01687996, ..., -0.05489433,\n",
              "         0.01371884,  0.04520964],\n",
              "       [ 0.04580186,  0.00427995,  0.06365997, ..., -0.04532593,\n",
              "         0.01539738,  0.06797412],\n",
              "       [ 0.06407946,  0.00896972, -0.06395225, ..., -0.03237554,\n",
              "        -0.00124098,  0.02909163],\n",
              "       ...,\n",
              "       [-0.06740418,  0.04015753,  0.03372011, ..., -0.0542163 ,\n",
              "        -0.02707728,  0.029973  ],\n",
              "       [ 0.00637474,  0.06874329,  0.01942719, ..., -0.04886399,\n",
              "         0.00256976, -0.02806403],\n",
              "       [ 0.03410461,  0.04210812, -0.04232227, ...,  0.06503583,\n",
              "        -0.02423177, -0.04210303]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF5SldJHLB4t",
        "colab_type": "code",
        "outputId": "38056623-f442-4007-c0a5-298603383528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCUu_BACpURE",
        "colab_type": "code",
        "outputId": "6f07a52e-08df-48f7-a41a-4ee9ddef8fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "biases[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH52rpzeLR38",
        "colab_type": "code",
        "outputId": "913dc3d2-0f40-463a-ce76-9d5c1edf00a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "biases.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPaP3uIyQpL",
        "colab_type": "text"
      },
      "source": [
        "#### Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWIBR66dQFgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wuZDVkEyUgS",
        "colab_type": "text"
      },
      "source": [
        "#### Training and Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ3JV4PULcaq",
        "colab_type": "code",
        "outputId": "7313d2f9-5403-4947-91bf-67a5505b34b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_fit = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.6995 - acc: 0.7705 - val_loss: 0.5347 - val_acc: 0.8194\n",
            "Epoch 2/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.4842 - acc: 0.8319 - val_loss: 0.4437 - val_acc: 0.8496\n",
            "Epoch 3/30\n",
            "55000/55000 [==============================] - 6s 106us/sample - loss: 0.4388 - acc: 0.8469 - val_loss: 0.4087 - val_acc: 0.8588\n",
            "Epoch 4/30\n",
            "55000/55000 [==============================] - 6s 108us/sample - loss: 0.4124 - acc: 0.8544 - val_loss: 0.3970 - val_acc: 0.8644\n",
            "Epoch 5/30\n",
            "55000/55000 [==============================] - 6s 107us/sample - loss: 0.3928 - acc: 0.8622 - val_loss: 0.3873 - val_acc: 0.8644\n",
            "Epoch 6/30\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.3770 - acc: 0.8678 - val_loss: 0.3742 - val_acc: 0.8680\n",
            "Epoch 7/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.3642 - acc: 0.8701 - val_loss: 0.3559 - val_acc: 0.8772\n",
            "Epoch 8/30\n",
            "55000/55000 [==============================] - 6s 110us/sample - loss: 0.3523 - acc: 0.8753 - val_loss: 0.3553 - val_acc: 0.8764\n",
            "Epoch 9/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.3425 - acc: 0.8777 - val_loss: 0.3654 - val_acc: 0.8676\n",
            "Epoch 10/30\n",
            "55000/55000 [==============================] - 6s 112us/sample - loss: 0.3328 - acc: 0.8816 - val_loss: 0.3448 - val_acc: 0.8786\n",
            "Epoch 11/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3249 - acc: 0.8833 - val_loss: 0.3399 - val_acc: 0.8818\n",
            "Epoch 12/30\n",
            "55000/55000 [==============================] - 6s 111us/sample - loss: 0.3169 - acc: 0.8866 - val_loss: 0.3497 - val_acc: 0.8766\n",
            "Epoch 13/30\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3098 - acc: 0.8887 - val_loss: 0.3268 - val_acc: 0.8808\n",
            "Epoch 14/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3030 - acc: 0.8914 - val_loss: 0.3416 - val_acc: 0.8776\n",
            "Epoch 15/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.2967 - acc: 0.8922 - val_loss: 0.3211 - val_acc: 0.8858\n",
            "Epoch 16/30\n",
            "55000/55000 [==============================] - 6s 111us/sample - loss: 0.2901 - acc: 0.8947 - val_loss: 0.3188 - val_acc: 0.8886\n",
            "Epoch 17/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.2852 - acc: 0.8965 - val_loss: 0.3123 - val_acc: 0.8902\n",
            "Epoch 18/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.2794 - acc: 0.8996 - val_loss: 0.3179 - val_acc: 0.8892\n",
            "Epoch 19/30\n",
            "55000/55000 [==============================] - 7s 124us/sample - loss: 0.2750 - acc: 0.9010 - val_loss: 0.3257 - val_acc: 0.8828\n",
            "Epoch 20/30\n",
            "55000/55000 [==============================] - 6s 108us/sample - loss: 0.2700 - acc: 0.9019 - val_loss: 0.3088 - val_acc: 0.8920\n",
            "Epoch 21/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.2652 - acc: 0.9040 - val_loss: 0.3031 - val_acc: 0.8944\n",
            "Epoch 22/30\n",
            "55000/55000 [==============================] - 6s 112us/sample - loss: 0.2596 - acc: 0.9055 - val_loss: 0.3145 - val_acc: 0.8852\n",
            "Epoch 23/30\n",
            "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2559 - acc: 0.9079 - val_loss: 0.3038 - val_acc: 0.8904\n",
            "Epoch 24/30\n",
            "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2512 - acc: 0.9089 - val_loss: 0.2962 - val_acc: 0.8962\n",
            "Epoch 25/30\n",
            "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2480 - acc: 0.9105 - val_loss: 0.3039 - val_acc: 0.8914\n",
            "Epoch 26/30\n",
            "55000/55000 [==============================] - 6s 107us/sample - loss: 0.2437 - acc: 0.9125 - val_loss: 0.2987 - val_acc: 0.8912\n",
            "Epoch 27/30\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.2398 - acc: 0.9132 - val_loss: 0.3016 - val_acc: 0.8924\n",
            "Epoch 28/30\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.2349 - acc: 0.9149 - val_loss: 0.2997 - val_acc: 0.8922\n",
            "Epoch 29/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.2318 - acc: 0.9156 - val_loss: 0.3072 - val_acc: 0.8886\n",
            "Epoch 30/30\n",
            "55000/55000 [==============================] - 6s 107us/sample - loss: 0.2288 - acc: 0.9171 - val_loss: 0.2924 - val_acc: 0.8952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zecCHL8QCQd",
        "colab_type": "code",
        "outputId": "3318e6d2-170e-4940-fdd3-a70f0fada0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(model_fit.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1) # plt.gca(): Get the current Axes instance on the current figure matching the given keyword args, or create one.\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEzCAYAAAALosttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfEbFWURExGdUnEVERHxGxVlERMRn/gcqCHHS3Zg9MgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwowOFo2VOPV",
        "colab_type": "code",
        "outputId": "3eac97e0-eb7a-4e92-cb80-e701843efd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 46us/sample - loss: 59.2613 - acc: 0.8583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[59.26126955986023, 0.8583]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6T08TxByhGW",
        "colab_type": "text"
      },
      "source": [
        "#### Using the Model to Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88imSlQinV-e",
        "colab_type": "code",
        "outputId": "06d2a2c5-f1a4-4d00-c7c7-a22c72b0d8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Using the Model to Make Predictions\n",
        "# Since we don’t have actual new instances, we will just use the first 3 instances of the test set:\n",
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P_jCsiBn8qd",
        "colab_type": "code",
        "outputId": "48e553ed-acd3-462a-81fc-56e1f7590432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# If you only care about the class with the highest estimated probability(even if that probability is quite low),\n",
        "# then you can use the predict_classes() method instead:\n",
        "y_pred = model.predict_classes(X_new)\n",
        "y_pred"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NKBDjGWoIyl",
        "colab_type": "code",
        "outputId": "fb8fc3a2-f813-4b67-bbbe-734e28976111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(class_names)[y_pred]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8htucGzbq39X",
        "colab_type": "code",
        "outputId": "771a0125-6df8-4d53-b8f8-cb4fd6012d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#  the classifier actually classified all three images correctly:\n",
        "y_test[:3]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byOyO3d7r3dB",
        "colab_type": "text"
      },
      "source": [
        "### Building a Regression MLP Using the Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_P-b9WArg-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use Scikit-Learn’s fetch_california_housing() function to load the data:\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87x-TNnmLoff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2d06ae9e-7745-4324-c6e3-d139f38ed67f"
      },
      "source": [
        "housing = fetch_california_housing()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n",
            "I0710 08:51:58.039066 139636251805568 california_housing.py:114] Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6A7krlxsrpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7AVzdn8LkOQ",
        "colab_type": "code",
        "outputId": "df2f22c1-0dd6-4d9e-bcdb-e8ada7e45c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# StandardScaler(): Standardize features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # fit_transform:　Fit to data, then transform it.  So after this step, the scaler object has the mean and std attribute of X_train\n",
        "X_valid_scaled = scaler.transform(X_valid) # Using the mean and std attribute of X_train to standardize X_valid\n",
        "X_test_scaled = scaler.transform(X_test) # Using the mean and std attribute of X_train to standardize X_test\n",
        "print(scaler.mean_)\n",
        "print(np.mean(X_train[:,0]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.86078633e+00  2.87113695e+01  5.43408177e+00  1.09832747e+00\n",
            "  1.41715926e+03  3.14697097e+00  3.56334625e+01 -1.19572295e+02]\n",
            "3.8607863307493546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEVfIsUBLkr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]), # the input_shape is start from index 1 of the X_train.shape, since the index 0 is the sample size\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wzlFxXLWNUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_PGfGjuMUpn",
        "colab_type": "code",
        "outputId": "1b403fde-969a-4c1f-a6fa-72bb098e24c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "model_fit = model.fit(X_train_scaled, y_train, epochs=20, validation_data = (X_valid_scaled, y_valid))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/20\n",
            "11610/11610 [==============================] - 1s 75us/sample - loss: 0.9452 - val_loss: 0.5647\n",
            "Epoch 2/20\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5319 - val_loss: 0.4971\n",
            "Epoch 3/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4911 - val_loss: 0.4721\n",
            "Epoch 4/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4668 - val_loss: 0.4479\n",
            "Epoch 5/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4507 - val_loss: 0.4340\n",
            "Epoch 6/20\n",
            "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4412 - val_loss: 0.4276\n",
            "Epoch 7/20\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4327 - val_loss: 0.4155\n",
            "Epoch 8/20\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4327 - val_loss: 0.4170\n",
            "Epoch 9/20\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4197 - val_loss: 0.4073\n",
            "Epoch 10/20\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4151 - val_loss: 0.4033\n",
            "Epoch 11/20\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4113 - val_loss: 0.4012\n",
            "Epoch 12/20\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4076 - val_loss: 0.3951\n",
            "Epoch 13/20\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4019 - val_loss: 0.3884\n",
            "Epoch 14/20\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3998 - val_loss: 0.3904\n",
            "Epoch 15/20\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3984 - val_loss: 0.3837\n",
            "Epoch 16/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3979 - val_loss: 0.4110\n",
            "Epoch 17/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4036 - val_loss: 0.3809\n",
            "Epoch 18/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4695 - val_loss: 0.3918\n",
            "Epoch 19/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3984 - val_loss: 0.3926\n",
            "Epoch 20/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3911 - val_loss: 0.3824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDJJLPpARdZ_",
        "colab_type": "code",
        "outputId": "6ca9d6fd-2120-432c-82c9-1f1a696a2d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mse_test = model.evaluate(X_test_scaled, y_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 26us/sample - loss: 0.3931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-FxTWgST4ur",
        "colab_type": "code",
        "outputId": "46b7adef-dc9d-4db1-cbc7-26b555d7c747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "X_new = X_test_scaled[:3] # pretend these are new instances\n",
        "y_pred = model.predict(X_new)\n",
        "y_pred"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6941538],\n",
              "       [0.9407015],\n",
              "       [4.116179 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiIsmvDzjb2r",
        "colab_type": "text"
      },
      "source": [
        "### Building Complex Models Using the Functional API\n",
        "p.331"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPBdtoY1pe4U",
        "colab_type": "text"
      },
      "source": [
        "One example of a non-sequential neural network is a **Wide & Deep neural network**.\n",
        "It connects all or part of the inputs directly to the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_-Cl9fpWGzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let’s build such a neural network to tackle the California housing problem:\n",
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation = 'relu')(input)\n",
        "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYJG3EogpZFy",
        "colab_type": "text"
      },
      "source": [
        "if we want to send a subset of the features through the wide path, and a different subset (possibly overlapping) through the deep path (see Figure 10-14)? In this case, one solution is to use **multiple inputs**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd-ZBrWWW2VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = keras.layers.Input(shape=[5])\n",
        "input_B = keras.layers.Input(shape=[6])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059di3dJZfs1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "4e11c92e-fc99-4653-f8a4-3a39cbb0aaf7"
      },
      "source": [
        "model.compile(loss='mse', optimizer='sgd')\n",
        "\n",
        "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
        "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
        "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/20\n",
            "11610/11610 [==============================] - 1s 69us/sample - loss: nan - val_loss: nan\n",
            "Epoch 2/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 3/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
            "Epoch 4/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 5/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 6/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 7/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 8/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 9/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 10/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 11/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 12/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 13/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 14/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 15/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 16/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 17/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 18/20\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
            "Epoch 19/20\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
            "Epoch 20/20\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
            "5160/5160 [==============================] - 0s 24us/sample - loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsivkeJb3w0a",
        "colab_type": "text"
      },
      "source": [
        "p.334   ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXQcJUudfvGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvM0bAI539mL",
        "colab_type": "text"
      },
      "source": [
        "### Building Dynamic Models Using the Subclassing API\n",
        "p.336"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eug3zEtQsBgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3pTrCMc4CDm",
        "colab_type": "text"
      },
      "source": [
        "### Saving and Restoring a Model\n",
        "p.337"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F-X1EWX7b9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving a trained Keras model is as simple as it gets:\n",
        "model.save(\"my_keras_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7C6GXPG7riv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the model\n",
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNsokpwt4OgS",
        "colab_type": "text"
      },
      "source": [
        "### Using Callbacks\n",
        "The `fit()` method accepts a **callbacks argument** that lets you specify a list of objects\n",
        "that Keras will call *during training at the start and end of training*, *at the start and end\n",
        "of each epoch* and even *before and after processing each batch*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqzfnixl4O0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [...] # build and compile the model\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
        "history = model.fit(X_train, y_train, epochs=10, callbacks =[checkpoint_cb])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Br_arr8Q6v",
        "colab_type": "text"
      },
      "source": [
        "set **`save_best_only=True`** when creating the **`ModelCheckpoint`**. In this case, it will only\n",
        "save your model when its performance on the validation set is the best so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzozeEdw8goQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
        "                                                set_best_only = True)\n",
        "history = model.fit(X_train, y_train, epochs = 10, \n",
        "                    validation_data = (X_valid, y_valid),\n",
        "                    callbacks = [checkpoint_cb])\n",
        "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZfp-9Sn8gwJ",
        "colab_type": "text"
      },
      "source": [
        "Another way to implement early stopping is to simply use the **`EarlyStopping`** call‐\n",
        "back. It will interrupt training when it measures no progress on the validation set for\n",
        "a number of epochs (defined by the **`patience`** argument), and it will optionally roll\n",
        "back to the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32wTyLMK8g2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B1SY-bRsBwq",
        "colab_type": "text"
      },
      "source": [
        "###Visualization Using TensorBoard\n",
        "p.339"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ylnC1bsCzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "root_logdir = os.path.join(os.curdir, 'my_logs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo18Tfk4sOMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "  \n",
        "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_01_16-11_28_43'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb9-ZnWpseTd",
        "colab_type": "code",
        "outputId": "b290489e-511f-4e3f-faa1-f22437e3bb74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# [...] # Build and compile your model\n",
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[tensorboard_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "55000/55000 [==============================] - 7s 119us/sample - loss: 0.7207 - acc: 0.7658 - val_loss: 0.5258 - val_acc: 0.8250\n",
            "Epoch 2/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.4900 - acc: 0.8283 - val_loss: 0.4537 - val_acc: 0.8426\n",
            "Epoch 3/30\n",
            "55000/55000 [==============================] - 6s 117us/sample - loss: 0.4428 - acc: 0.8450 - val_loss: 0.4164 - val_acc: 0.8584\n",
            "Epoch 4/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.4141 - acc: 0.8538 - val_loss: 0.4006 - val_acc: 0.8610\n",
            "Epoch 5/30\n",
            "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3933 - acc: 0.8623 - val_loss: 0.3828 - val_acc: 0.8672\n",
            "Epoch 6/30\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3788 - acc: 0.8661 - val_loss: 0.3762 - val_acc: 0.8690\n",
            "Epoch 7/30\n",
            "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3648 - acc: 0.8707 - val_loss: 0.3672 - val_acc: 0.8710\n",
            "Epoch 8/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3541 - acc: 0.8743 - val_loss: 0.3670 - val_acc: 0.8694\n",
            "Epoch 9/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3427 - acc: 0.8772 - val_loss: 0.3558 - val_acc: 0.8760\n",
            "Epoch 10/30\n",
            "55000/55000 [==============================] - 7s 122us/sample - loss: 0.3339 - acc: 0.8810 - val_loss: 0.3588 - val_acc: 0.8750\n",
            "Epoch 11/30\n",
            "55000/55000 [==============================] - 7s 128us/sample - loss: 0.3259 - acc: 0.8833 - val_loss: 0.3463 - val_acc: 0.8776\n",
            "Epoch 12/30\n",
            "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3179 - acc: 0.8860 - val_loss: 0.3419 - val_acc: 0.8758\n",
            "Epoch 13/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3111 - acc: 0.8889 - val_loss: 0.3256 - val_acc: 0.8830\n",
            "Epoch 14/30\n",
            "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3032 - acc: 0.8915 - val_loss: 0.3261 - val_acc: 0.8824\n",
            "Epoch 15/30\n",
            "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2974 - acc: 0.8932 - val_loss: 0.3367 - val_acc: 0.8780\n",
            "Epoch 16/30\n",
            "55000/55000 [==============================] - 7s 125us/sample - loss: 0.2911 - acc: 0.8960 - val_loss: 0.3499 - val_acc: 0.8706\n",
            "Epoch 17/30\n",
            "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2856 - acc: 0.8976 - val_loss: 0.3218 - val_acc: 0.8840\n",
            "Epoch 18/30\n",
            "55000/55000 [==============================] - 6s 111us/sample - loss: 0.2803 - acc: 0.8987 - val_loss: 0.3214 - val_acc: 0.8848\n",
            "Epoch 19/30\n",
            "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2743 - acc: 0.9017 - val_loss: 0.3138 - val_acc: 0.8876\n",
            "Epoch 20/30\n",
            "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2695 - acc: 0.9027 - val_loss: 0.3148 - val_acc: 0.8850\n",
            "Epoch 21/30\n",
            "55000/55000 [==============================] - 7s 120us/sample - loss: 0.2647 - acc: 0.9048 - val_loss: 0.3059 - val_acc: 0.8880\n",
            "Epoch 22/30\n",
            "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2591 - acc: 0.9069 - val_loss: 0.3157 - val_acc: 0.8844\n",
            "Epoch 23/30\n",
            "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2550 - acc: 0.9077 - val_loss: 0.3065 - val_acc: 0.8844\n",
            "Epoch 24/30\n",
            "55000/55000 [==============================] - 7s 120us/sample - loss: 0.2503 - acc: 0.9104 - val_loss: 0.3146 - val_acc: 0.8854\n",
            "Epoch 25/30\n",
            "55000/55000 [==============================] - 7s 123us/sample - loss: 0.2464 - acc: 0.9113 - val_loss: 0.2991 - val_acc: 0.8928\n",
            "Epoch 26/30\n",
            "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2428 - acc: 0.9118 - val_loss: 0.3108 - val_acc: 0.8898\n",
            "Epoch 27/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.2387 - acc: 0.9140 - val_loss: 0.3037 - val_acc: 0.8920\n",
            "Epoch 28/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.2343 - acc: 0.9153 - val_loss: 0.2988 - val_acc: 0.8882\n",
            "Epoch 29/30\n",
            "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2300 - acc: 0.9167 - val_loss: 0.3127 - val_acc: 0.8890\n",
            "Epoch 30/30\n",
            "55000/55000 [==============================] - 7s 124us/sample - loss: 0.2264 - acc: 0.9185 - val_loss: 0.2985 - val_acc: 0.8930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVqUbJ2bsrFh",
        "colab_type": "code",
        "outputId": "a5130783-2963-48aa-a8df-d8a8fa6a4839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!tensorboard --logdir=./my_logs --port=6006\n",
        "!TensorBoard 2.0.0 at http://mycomputer.local:6006"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.14.0 at http://c6baa84c8a09:6006/ (Press CTRL+C to quit)\n",
            "^C\n",
            "/bin/bash: TensorBoard: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D00CL6puTZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2KmBSr6v0XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMXwbSUfvzy4",
        "colab_type": "text"
      },
      "source": [
        "## Fine-Tuning Neural Network Hyperparameters\n",
        "p.342"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L29laYnjxHxH",
        "colab_type": "text"
      },
      "source": [
        "The flexibility of neural networks is also one of their main drawbacks: there are many\n",
        "hyperparameters to tweak.  How do you know what combination of hyperpara‐\n",
        "meters is the best for your task?\n",
        "One option is to simply try many combinations of hyperparameters and see which\n",
        "one works best on the validation set (or using K-fold cross-validation).\n",
        "For this, one approach is simply use **GridSearchCV** or **RandomizedSearchCV** to explore the hyper‐\n",
        "parameter space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcjSB7jqxc8D",
        "colab_type": "text"
      },
      "source": [
        "For this, we need to wrap our Keras models in objects that mimic regular Scikit-Learn regressors. \n",
        "</br>The first step is to create a function that will build and compile a Keras model, given a set of hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pck-Az9Mv2p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "  model = keras.models.Sequential()\n",
        "  options = {'input_shape': input_shape} # The options dict is used to ensure that the first layer is properly given the input shape\n",
        "  for layers in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation='relu', **options))\n",
        "    options={}\n",
        "  model.add(keras.layers.Dense(1, **options))\n",
        "  optimizer = keras.optimizers.SGD(learning_rate)\n",
        "  model.compile(loss='mse', optimizer=optimizer)\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3e3yT-lD5cX",
        "colab_type": "text"
      },
      "source": [
        "Next, let’s create a KerasRegressor based on this build_model() function:\n",
        "<br/>The KerasRegressor object is a thin wrapper around the Keras model built using\n",
        "build_model(). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PeQnC0iDuLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtrteuEPGptt",
        "colab_type": "text"
      },
      "source": [
        " it will just use the default hyperparameters we defined in build_model(). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9CFJN0ZERk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f915cc17-8ac8-490f-8cba-1608b4cdf840"
      },
      "source": [
        "keras_reg.fit(X_train_scaled, y_train, epochs=10,\n",
        "              validation_data=(X_valid_scaled, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "mse_test = keras_reg.score(X_test_scaled, y_test)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/10\n",
            "11610/11610 [==============================] - 1s 79us/sample - loss: 1.2247 - val_loss: 0.7009\n",
            "Epoch 2/10\n",
            "11610/11610 [==============================] - 1s 43us/sample - loss: 0.6399 - val_loss: 0.5999\n",
            "Epoch 3/10\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.5742 - val_loss: 0.5514\n",
            "Epoch 4/10\n",
            "11610/11610 [==============================] - 1s 43us/sample - loss: 0.5389 - val_loss: 0.5191\n",
            "Epoch 5/10\n",
            "11610/11610 [==============================] - 1s 43us/sample - loss: 0.5297 - val_loss: 0.5050\n",
            "Epoch 6/10\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5021 - val_loss: 0.4866\n",
            "Epoch 7/10\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4915 - val_loss: 0.4767\n",
            "Epoch 8/10\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4830 - val_loss: 0.4690\n",
            "Epoch 9/10\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4774 - val_loss: 0.4627\n",
            "Epoch 10/10\n",
            "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4725 - val_loss: 0.4564\n",
            "5160/5160 [==============================] - 0s 23us/sample - loss: 0.4653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7ygnX7EHTkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "958dd1e5-304d-48f2-8dbf-8a3cd8399acd"
      },
      "source": [
        "X_new = X_test_scaled[:3]\n",
        "y_pred = keras_reg.predict(X_new)\n",
        "y_pred"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.1040471 , 0.98380256, 3.876338  ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAK4OrmHJHqU",
        "colab_type": "text"
      },
      "source": [
        "we want to train hundreds of variants and see which one performs best on the validation\n",
        "set. \n",
        "<br/>Since there are many hyperparameters, it is preferable to use a randomized search\n",
        "rather than grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-jadRTKI5gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAYaNmWyJjMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_distribs = {\n",
        "    \"n_hidden\":[0,1,2,3],\n",
        "    \"n_neurons\":np.arange(1,100),\n",
        "    \"learning_rate\":reciprocal(3e-4, 3e-2),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAK7KL6UKvlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
        "rnd_search_cv.fit(X_train_scaled, y_train, epochs=30,\n",
        "                  validation_data=(X_valid_scaled, y_valid),\n",
        "                  callbacks=keras.callbacks.EarlyStopping(patience=10))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}